{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITMAL Exercise\n",
    "\n",
    "REVISIONS| |\n",
    "---------| |\n",
    "2018-0318| CEF, initial.\n",
    "2018-0321| CEF, synced with MLP moon exercise.\n",
    "2018-0323| CEF, minor updated and spell checked.\n",
    "2019-0930| CEF, updated for ITMAL E19.\n",
    "\n",
    "\n",
    "## Keras Multi-Layer Perceptrons (MLP's) on MNIST-data\n",
    "\n",
    "\n",
    "### Qa Using a Keras MLP on the MNIST-data\n",
    "\n",
    "Now, make a Keras `Sequential` model and fit it to the MNIST data, re-using as much of the code form the `mlp_moon.ipynb` as you can.\n",
    "\n",
    "Then try to change the number of hidden layers and the neurons in each layer, looking for increases in test accuracy via ``score``. \n",
    "\n",
    "Publish your best score for your model in Blackboard, see link under L06. We use categorical accuracy for score---eventhough a $F_1$ score could say more. Publish you result like\n",
    "```\n",
    "   ITMALGrpXY: score=0.76, a 10-20-30-20-10 MLP, takes looong to train\n",
    "```\n",
    "or similar\n",
    "\n",
    "\n",
    "NOTE: you probably need to scale/normalize the MNIST data before a fit, and no 2D-decision boundaries can be drawn from the 784-dimension MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cnt = 0\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def MNIST_GetDataSet():\n",
    "    # Load data from https://www.openml.org/d/554\n",
    "    X, y = fetch_openml('mnist_784', return_X_y=1) # needs to return X, y, replace '??' with suitable parameters! \n",
    "    # Convert at scale (not always needed)\n",
    "    #X = X / 255.\n",
    "    return (X, y)\n",
    "\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    global fig_cnt\n",
    "    plt.figure(fig_cnt)\n",
    "    fig_cnt += 1\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "X, y = MNIST_GetDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 104,938\n",
      "Trainable params: 104,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49000 samples, validate on 21000 samples\n",
      "Epoch 1/100\n",
      "49000/49000 [==============================] - 10s 208us/step - loss: 0.6897 - categorical_accuracy: 0.7753 - mean_squared_error: 0.0303 - mean_absolute_error: 0.0630 - val_loss: 0.3477 - val_categorical_accuracy: 0.9015 - val_mean_squared_error: 0.0149 - val_mean_absolute_error: 0.0287\n",
      "Epoch 2/100\n",
      "49000/49000 [==============================] - 6s 114us/step - loss: 0.3070 - categorical_accuracy: 0.9117 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0271 - val_loss: 0.3683 - val_categorical_accuracy: 0.8908 - val_mean_squared_error: 0.0164 - val_mean_absolute_error: 0.0308\n",
      "Epoch 3/100\n",
      "49000/49000 [==============================] - 4s 91us/step - loss: 0.2646 - categorical_accuracy: 0.9225 - mean_squared_error: 0.0117 - mean_absolute_error: 0.0229 - val_loss: 0.2604 - val_categorical_accuracy: 0.9261 - val_mean_squared_error: 0.0113 - val_mean_absolute_error: 0.0231\n",
      "Epoch 4/100\n",
      "49000/49000 [==============================] - 5s 99us/step - loss: 0.2410 - categorical_accuracy: 0.9295 - mean_squared_error: 0.0107 - mean_absolute_error: 0.0208 - val_loss: 0.3304 - val_categorical_accuracy: 0.9103 - val_mean_squared_error: 0.0138 - val_mean_absolute_error: 0.0239\n",
      "Epoch 5/100\n",
      "49000/49000 [==============================] - 5s 100us/step - loss: 0.2297 - categorical_accuracy: 0.9332 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0194 - val_loss: 0.2665 - val_categorical_accuracy: 0.9281 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0227\n",
      "Epoch 6/100\n",
      "49000/49000 [==============================] - 5s 100us/step - loss: 0.2122 - categorical_accuracy: 0.9376 - mean_squared_error: 0.0094 - mean_absolute_error: 0.0182 - val_loss: 0.2845 - val_categorical_accuracy: 0.9185 - val_mean_squared_error: 0.0124 - val_mean_absolute_error: 0.0217\n",
      "Epoch 7/100\n",
      "49000/49000 [==============================] - 5s 99us/step - loss: 0.2047 - categorical_accuracy: 0.9402 - mean_squared_error: 0.0091 - mean_absolute_error: 0.0174 - val_loss: 0.2728 - val_categorical_accuracy: 0.9215 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0224\n",
      "Epoch 8/100\n",
      "49000/49000 [==============================] - 5s 107us/step - loss: 0.2021 - categorical_accuracy: 0.9409 - mean_squared_error: 0.0090 - mean_absolute_error: 0.0170 - val_loss: 0.2158 - val_categorical_accuracy: 0.9396 - val_mean_squared_error: 0.0092 - val_mean_absolute_error: 0.0167\n",
      "Epoch 9/100\n",
      "49000/49000 [==============================] - 5s 101us/step - loss: 0.1969 - categorical_accuracy: 0.9424 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0165 - val_loss: 0.2485 - val_categorical_accuracy: 0.9309 - val_mean_squared_error: 0.0104 - val_mean_absolute_error: 0.0181\n",
      "Epoch 10/100\n",
      "49000/49000 [==============================] - 5s 96us/step - loss: 0.1916 - categorical_accuracy: 0.9435 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0161 - val_loss: 0.2344 - val_categorical_accuracy: 0.9377 - val_mean_squared_error: 0.0096 - val_mean_absolute_error: 0.0162\n",
      "Epoch 11/100\n",
      "49000/49000 [==============================] - 5s 94us/step - loss: 0.1888 - categorical_accuracy: 0.9448 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0156 - val_loss: 0.2335 - val_categorical_accuracy: 0.9364 - val_mean_squared_error: 0.0098 - val_mean_absolute_error: 0.0172\n",
      "Epoch 12/100\n",
      "49000/49000 [==============================] - 5s 105us/step - loss: 0.1875 - categorical_accuracy: 0.9447 - mean_squared_error: 0.0083 - mean_absolute_error: 0.0155 - val_loss: 0.2834 - val_categorical_accuracy: 0.9189 - val_mean_squared_error: 0.0124 - val_mean_absolute_error: 0.0207\n",
      "Epoch 13/100\n",
      "49000/49000 [==============================] - 8s 158us/step - loss: 0.1813 - categorical_accuracy: 0.9455 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0151 - val_loss: 0.2537 - val_categorical_accuracy: 0.9325 - val_mean_squared_error: 0.0104 - val_mean_absolute_error: 0.0191: 0.1829 - categorical_accuracy: 0.9434 - mean_squared_error: 0.0084 - me - ETA: 4s - loss: 0.1885 - categorical_accuracy: 0.9423 - mean_squared_error: 0 - ETA: 3s - loss: 0.1817 - categorical_accuracy: 0.9447 - mean_squared_error: 0. - ETA: 0s - loss: 0.1803 - categorical_accuracy: 0.9454 - mean_squared_error: 0.0082 - mean_absolute_erro\n",
      "Epoch 14/100\n",
      "49000/49000 [==============================] - 5s 99us/step - loss: 0.1748 - categorical_accuracy: 0.9481 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0145 - val_loss: 0.2476 - val_categorical_accuracy: 0.9326 - val_mean_squared_error: 0.0104 - val_mean_absolute_error: 0.0177\n",
      "Epoch 15/100\n",
      "49000/49000 [==============================] - 5s 104us/step - loss: 0.1725 - categorical_accuracy: 0.9483 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0143 - val_loss: 0.2408 - val_categorical_accuracy: 0.9350 - val_mean_squared_error: 0.0099 - val_mean_absolute_error: 0.0166\n",
      "Epoch 16/100\n",
      "49000/49000 [==============================] - 6s 114us/step - loss: 0.1724 - categorical_accuracy: 0.9491 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0143 - val_loss: 0.2229 - val_categorical_accuracy: 0.9402 - val_mean_squared_error: 0.0091 - val_mean_absolute_error: 0.0152\n",
      "Epoch 17/100\n",
      "49000/49000 [==============================] - 5s 106us/step - loss: 0.1661 - categorical_accuracy: 0.9512 - mean_squared_error: 0.0074 - mean_absolute_error: 0.0137 - val_loss: 0.2481 - val_categorical_accuracy: 0.9382 - val_mean_squared_error: 0.0098 - val_mean_absolute_error: 0.0167\n",
      "Epoch 18/100\n",
      "49000/49000 [==============================] - 5s 95us/step - loss: 0.1641 - categorical_accuracy: 0.9519 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0135 - val_loss: 0.2281 - val_categorical_accuracy: 0.9396 - val_mean_squared_error: 0.0093 - val_mean_absolute_error: 0.0154\n",
      "Epoch 19/100\n",
      "49000/49000 [==============================] - 5s 112us/step - loss: 0.1644 - categorical_accuracy: 0.9520 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0135 - val_loss: 0.2314 - val_categorical_accuracy: 0.9410 - val_mean_squared_error: 0.0092 - val_mean_absolute_error: 0.0149\n",
      "Epoch 20/100\n",
      "49000/49000 [==============================] - 5s 105us/step - loss: 0.1595 - categorical_accuracy: 0.9535 - mean_squared_error: 0.0071 - mean_absolute_error: 0.0131 - val_loss: 0.2527 - val_categorical_accuracy: 0.9345 - val_mean_squared_error: 0.0101 - val_mean_absolute_error: 0.0175\n",
      "Epoch 21/100\n",
      "36864/49000 [=====================>........] - ETA: 1s - loss: 0.1623 - categorical_accuracy: 0.9522 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0135- ETA: 3s - loss: 0.1522 - categorical_accuracy: 0.9539 - mean_squared_erro"
     ]
    }
   ],
   "source": [
    "#from libitmal import kernelfuns as itmalkernelfuns\n",
    "#itmalkernelfuns.EnableGPU()                              \n",
    "#itmalkernelfuns.DisableGPU()   \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "np.random.seed(1337)\n",
    "num_classes = 10\n",
    "\n",
    "# Build Keras model \n",
    "model = Sequential()\n",
    "#model.add(Dense(input_dim=784, units=8, activation=\"tanh\", kernel_initializer=\"normal\"))\n",
    "#model.add(Dense(units=2, activation=\"softmax\", input_shape=(784,)))\n",
    "model.add(Dense(units=128, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "optimizer = Adam(lr=0.1)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizer,\n",
    "              metrics=['categorical_accuracy', 'mean_squared_error', 'mean_absolute_error'])\n",
    "model.summary()\n",
    "# Make data\n",
    "X = X/255.0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1337)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "assert y.ndim==1\n",
    "assert y_train.ndim==2\n",
    "assert y_test.ndim ==2\n",
    "\n",
    "# Train\n",
    "VERBOSE     = 1\n",
    "EPOCHS      = 100\n",
    "\n",
    "start = time()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 128, epochs=EPOCHS, verbose=VERBOSE)\n",
    "t = time()-start\n",
    "\n",
    "print(f\"OK, training time={t:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(history.history)\n",
    "score = model.evaluate(X_test, y_test_binary, verbose=0)\n",
    "\n",
    "print(f\"Training time: {t:0.1f} sec\")\n",
    "print(f\"Test loss:     {score[0]}\") # loss is score 0 by definition?\n",
    "print(f\"Test accuracy: {score[1]}\")\n",
    "print(f\"All scores in history: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test run 1 (epochs = 2):\n",
    "* Training time: 60.5 sec\n",
    "* Test loss:     14.30365825471424\n",
    "* Test accuracy: 0.11257142857142857\n",
    "* All scores in history: [14.30365825471424, 0.11257142857142857, 0.1774857268674033, 0.1774857268674033]\n",
    "\n",
    "#### Test run 1 (epochs = 10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
