The confusion matrix utilizes multiple equations to evaluate the algorithms prediction purely on statistical data.   
Through this exercise we have gone through some ways of evaluation: accuracy, sensitivity, F1 score, and precision.
This helps us understand the different trade-offs of the algorithm, it might have a high accuracy but if it 
isn't also reflected in the sensitivity in the confusion matrix, then we might need to re-evaluate the approach.  
These techniques will help us understand how our algorithm behaves on data, as our algorithm might have an 
unbalanced prediction and help us spot if our algorithm is biased towards any data.
We see through this exercise that we need human intuition to decode and understand the results from the confusion matrix 
and how to improve the algorithm's prediction.
The examples in these exercises are controlled, and we have a target value to achieve with our algorithms, 
but when we start our project it's nice to go through what values we can expect and se how our values can trick us
due to bias of the algorithm etc. 
